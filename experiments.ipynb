{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "171fd4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples: 110,481\n",
      "Validation examples: 13,810\n",
      "Test examples: 13,811\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load splits\n",
    "train_df = pd.read_csv(\"./data/neural_column_mapping_medium_train.csv\")\n",
    "val_df = pd.read_csv(\"./data/neural_column_mapping_medium_val.csv\")\n",
    "test_df = pd.read_csv(\"./data/neural_column_mapping_medium_test.csv\")\n",
    "\n",
    "print(f\"Training examples: {len(train_df):,}\")\n",
    "print(f\"Validation examples: {len(val_df):,}\")\n",
    "print(f\"Test examples: {len(test_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b4efd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prosekutor/projects/ontology-mapping/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel\n",
    "\n",
    "class SiameseColumnMapper(nn.Module):\n",
    "    def __init__(self, model_name='sentence-transformers/all-MiniLM-L6-v2'):\n",
    "        super().__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(model_name)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(768, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, raw_tokens, standard_tokens):\n",
    "        # Encode both inputs\n",
    "        raw_emb = self.encoder(**raw_tokens).pooler_output\n",
    "        std_emb = self.encoder(**standard_tokens).pooler_output\n",
    "        \n",
    "        # Compute similarity features\n",
    "        diff = torch.abs(raw_emb - std_emb)\n",
    "        prod = raw_emb * std_emb\n",
    "        \n",
    "        # Concatenate features\n",
    "        features = torch.cat([raw_emb, std_emb, diff, prod], dim=1)\n",
    "        \n",
    "        # Classify\n",
    "        return self.classifier(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b198802e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEncoderMapper(nn.Module):\n",
    "    def __init__(self, model_name='distilbert-base-uncased'):\n",
    "        super().__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(model_name)\n",
    "        self.classifier = nn.Linear(768, 1)\n",
    "    \n",
    "    def forward(self, input_tokens):\n",
    "        # Input: \"[raw_col] [SEP] [standard_col]\"\n",
    "        outputs = self.encoder(**input_tokens)\n",
    "        return torch.sigmoid(self.classifier(outputs.pooler_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd3b45d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskColumnMapper(nn.Module):\n",
    "    def __init__(self, num_domains=7):\n",
    "        super().__init__()\n",
    "        self.shared_encoder = AutoModel.from_pretrained('all-MiniLM-L6-v2')\n",
    "        \n",
    "        # Task-specific heads\n",
    "        self.similarity_head = nn.Linear(768*4, 1)  # Main matching task\n",
    "        self.domain_head = nn.Linear(768, num_domains)  # Domain classification\n",
    "        self.confidence_head = nn.Linear(768*4, 1)  # Confidence estimation\n",
    "    \n",
    "    def forward(self, raw_tokens, standard_tokens, domain_labels=None):\n",
    "        raw_emb = self.shared_encoder(**raw_tokens).pooler_output\n",
    "        std_emb = self.shared_encoder(**standard_tokens).pooler_output\n",
    "        \n",
    "        # Similarity features\n",
    "        diff = torch.abs(raw_emb - std_emb)\n",
    "        prod = raw_emb * std_emb\n",
    "        sim_features = torch.cat([raw_emb, std_emb, diff, prod], dim=1)\n",
    "        \n",
    "        # Multi-task outputs\n",
    "        similarity = torch.sigmoid(self.similarity_head(sim_features))\n",
    "        domain_pred = self.domain_head(raw_emb)\n",
    "        confidence = torch.sigmoid(self.confidence_head(sim_features))\n",
    "        \n",
    "        return {\n",
    "            'similarity': similarity,\n",
    "            'domain': domain_pred,\n",
    "            'confidence': confidence\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89cd259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def train_model(model, train_loader, val_loader, epochs=10):\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(batch['raw_tokens'], batch['standard_tokens'])\n",
    "            loss = criterion(outputs.squeeze(), batch['labels'].float())\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_predictions = []\n",
    "        val_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                outputs = model(batch['raw_tokens'], batch['standard_tokens'])\n",
    "                predictions = (outputs.squeeze() > 0.5).cpu().numpy()\n",
    "                \n",
    "                val_predictions.extend(predictions)\n",
    "                val_labels.extend(batch['labels'].cpu().numpy())\n",
    "        \n",
    "        # Metrics\n",
    "        accuracy = accuracy_score(val_labels, val_predictions)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            val_labels, val_predictions, average='binary'\n",
    "        )\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        print(f\"  Train Loss: {train_loss/len(train_loader):.4f}\")\n",
    "        print(f\"  Val Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"  Val F1: {f1:.4f}\")\n",
    "        \n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            torch.save(model.state_dict(), 'best_column_mapper.pth')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14d84678",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseColumnMapper(nn.Module):\n",
    "    def __init__(self, model_name='sentence-transformers/all-MiniLM-L6-v2'):\n",
    "        super().__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(model_name)\n",
    "        emb_size = self.encoder.config.hidden_size  # dynamically get embedding size\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(emb_size*4, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, raw_tokens, standard_tokens):\n",
    "        raw_emb = self.encoder(**raw_tokens).pooler_output\n",
    "        std_emb = self.encoder(**standard_tokens).pooler_output\n",
    "\n",
    "        diff = torch.abs(raw_emb - std_emb)\n",
    "        prod = raw_emb * std_emb\n",
    "\n",
    "        features = torch.cat([raw_emb, std_emb, diff, prod], dim=1)\n",
    "        return self.classifier(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd47183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ColumnMappingDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer_name='sentence-transformers/all-MiniLM-L6-v2', max_length=32):\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        raw_text = str(row['raw_column_name'])\n",
    "        std_text = str(row['standard_column_name'])\n",
    "        label = float(row['is_match'])\n",
    "\n",
    "        raw_tokens = self.tokenizer(raw_text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        std_tokens = self.tokenizer(std_text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "\n",
    "        raw_tokens = {k: v.squeeze(0) for k, v in raw_tokens.items()}\n",
    "        std_tokens = {k: v.squeeze(0) for k, v in std_tokens.items()}\n",
    "\n",
    "        return {'raw_tokens': raw_tokens, 'standard_tokens': std_tokens, 'label': torch.tensor(label, dtype=torch.float)}\n",
    "\n",
    "def collate_fn(batch):\n",
    "    batch_raw = {key: torch.stack([item['raw_tokens'][key] for item in batch]) for key in batch[0]['raw_tokens']}\n",
    "    batch_std = {key: torch.stack([item['standard_tokens'][key] for item in batch]) for key in batch[0]['standard_tokens']}\n",
    "    labels = torch.stack([item['label'] for item in batch])\n",
    "    return batch_raw, batch_std, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89a5a668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_siamese(model, train_loader, val_loader, epochs=5, lr=2e-5, device='cuda'):\n",
    "    model.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    best_val_acc = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch_raw, batch_std, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "            batch_raw = {k: v.to(device) for k, v in batch_raw.items()}\n",
    "            batch_std = {k: v.to(device) for k, v in batch_std.items()}\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_raw, batch_std).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        with torch.no_grad():\n",
    "            for batch_raw, batch_std, labels in val_loader:\n",
    "                batch_raw = {k: v.to(device) for k, v in batch_raw.items()}\n",
    "                batch_std = {k: v.to(device) for k, v in batch_std.items()}\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(batch_raw, batch_std).squeeze()\n",
    "                preds = (outputs > 0.5).float()\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_acc = accuracy_score(val_labels, val_preds)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(val_labels, val_preds, average='binary')\n",
    "\n",
    "        print(f\"Epoch {epoch+1} | Loss: {avg_loss:.4f} | Val Acc: {val_acc:.4f} | F1: {f1:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_siamese_column_mapper.pth')\n",
    "            print(\"Best model saved!\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de8837b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 3453/3453 [03:47<00:00, 15.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 0.2260 | Val Acc: 0.9642 | F1: 0.9198\n",
      "Best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 3453/3453 [03:50<00:00, 14.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Loss: 0.0806 | Val Acc: 0.9755 | F1: 0.9443\n",
      "Best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 3453/3453 [03:45<00:00, 15.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Loss: 0.0548 | Val Acc: 0.9779 | F1: 0.9504\n",
      "Best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 3453/3453 [03:50<00:00, 15.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Loss: 0.0411 | Val Acc: 0.9794 | F1: 0.9534\n",
      "Best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 3453/3453 [03:37<00:00, 15.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Loss: 0.0345 | Val Acc: 0.9811 | F1: 0.9569\n",
      "Best model saved!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load dataset\n",
    "train_df = pd.read_csv(\"./data/neural_column_mapping_medium_train.csv\")\n",
    "val_df = pd.read_csv(\"./data/neural_column_mapping_medium_val.csv\")\n",
    "\n",
    "# Prepare datasets and loaders\n",
    "train_dataset = ColumnMappingDataset(train_df)\n",
    "val_dataset = ColumnMappingDataset(val_df)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# Initialize model\n",
    "model = SiameseColumnMapper(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Train\n",
    "trained_model = train_siamese(model, train_loader, val_loader, epochs=5, device='cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eab1e284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load trained model\n",
    "model = SiameseColumnMapper(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "model.load_state_dict(torch.load('best_siamese_column_mapper.pth', map_location='cpu'))\n",
    "model.eval()\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4adcd926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_top_k(model, tokenizer, raw_column, standard_columns, k=3, device='cpu', max_length=32):\n",
    "    \"\"\"\n",
    "    Predict top-k standard columns for a raw column\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    results = []\n",
    "\n",
    "    for std_col in standard_columns:\n",
    "        # Tokenize pair\n",
    "        raw_tokens = tokenizer(\n",
    "            raw_column, truncation=True, padding='max_length', max_length=max_length, return_tensors='pt'\n",
    "        )\n",
    "        std_tokens = tokenizer(\n",
    "            std_col, truncation=True, padding='max_length', max_length=max_length, return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        # Remove batch dim\n",
    "        raw_tokens = {k: v.to(device) for k, v in raw_tokens.items()}\n",
    "        std_tokens = {k: v.to(device) for k, v in std_tokens.items()}\n",
    "\n",
    "        # Predict similarity\n",
    "        with torch.no_grad():\n",
    "            score = model(raw_tokens, std_tokens).item()\n",
    "\n",
    "        results.append({'standard_column': std_col, 'confidence': score})\n",
    "\n",
    "    # Sort by confidence\n",
    "    results.sort(key=lambda x: x['confidence'], reverse=True)\n",
    "    return results[:k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3fda699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'standard_column': 'warranty_period', 'confidence': 0.99979168176651}\n",
      "{'standard_column': 'shipping_state', 'confidence': 0.03150755539536476}\n",
      "{'standard_column': 'order_date', 'confidence': 0.03122042305767536}\n"
     ]
    }
   ],
   "source": [
    "# Example raw column\n",
    "raw_col = \"warranty\"\n",
    "\n",
    "# List of all possible standard columns\n",
    "standard_cols = [\n",
    "    \"merchant_id\",\n",
    "    \"warehouse_location\",\n",
    "    \"selling_price\",\n",
    "    \"order_id\",\n",
    "    \"account_number\",\n",
    "    \"transaction_amount\",\n",
    "    \"fees\",\n",
    "    \"opening_date\",\n",
    "    \"manager_id\",\n",
    "    \"product_rating\",\n",
    "    \"account_status\",\n",
    "    \"registration_date\",\n",
    "    \"color\",\n",
    "    \"shipping_city\",\n",
    "    \"tax_amount\",\n",
    "    \"authorization_code\",\n",
    "    \"item_id\",\n",
    "    \"customer_id\",\n",
    "    \"order_total\",\n",
    "    \"account_balance\",\n",
    "    \"hire_date\",\n",
    "    \"customer_name\",\n",
    "    \"performance_rating\",\n",
    "    \"brand_name\",\n",
    "    \"transaction_type\",\n",
    "    \"product_category\",\n",
    "    \"currency_code\",\n",
    "    \"order_source\",\n",
    "    \"chargeback_flag\",\n",
    "    \"product_price\",\n",
    "    \"customer_type\",\n",
    "    \"actual_delivery\",\n",
    "    \"shipping_zip\",\n",
    "    \"employee_id\",\n",
    "    \"swift_code\",\n",
    "    \"unit_cost\",\n",
    "    \"discount_amount\",\n",
    "    \"transaction_date\",\n",
    "    \"salary\",\n",
    "    \"item_category\",\n",
    "    \"batch_number\",\n",
    "    \"model_number\",\n",
    "    \"reference_number\",\n",
    "    \"interest_rate\",\n",
    "    \"product_name\",\n",
    "    \"order_status\",\n",
    "    \"last_sold_date\",\n",
    "    \"quantity_available\",\n",
    "    \"customer_state\",\n",
    "    \"created_date\",\n",
    "    \"last_updated\",\n",
    "    \"payment_method\",\n",
    "    \"termination_date\",\n",
    "    \"delivery_date\",\n",
    "    \"product_id\",\n",
    "    \"shipping_cost\",\n",
    "    \"customer_segment\",\n",
    "    \"routing_number\",\n",
    "    \"supplier_id\",\n",
    "    \"iban\",\n",
    "    \"date_of_birth\",\n",
    "    \"last_login_date\",\n",
    "    \"review_count\",\n",
    "    \"years_experience\",\n",
    "    \"annual_fee\",\n",
    "    \"account_holder_name\",\n",
    "    \"order_date\",\n",
    "    \"shipping_address\",\n",
    "    \"item_code\",\n",
    "    \"occupation\",\n",
    "    \"account_id\",\n",
    "    \"gender\",\n",
    "    \"transaction_id\",\n",
    "    \"account_type\",\n",
    "    \"closing_date\",\n",
    "    \"employee_name\",\n",
    "    \"education_level\",\n",
    "    \"product_description\",\n",
    "    \"card_last_four\",\n",
    "    \"item_subcategory\",\n",
    "    \"skill_level\",\n",
    "    \"lead_time_days\",\n",
    "    \"phone_extension\",\n",
    "    \"office_location\",\n",
    "    \"employment_status\",\n",
    "    \"benefits_eligible\",\n",
    "    \"customer_city\",\n",
    "    \"customer_email\",\n",
    "    \"minimum_balance\",\n",
    "    \"item_name\",\n",
    "    \"reorder_point\",\n",
    "    \"monthly_fee\",\n",
    "    \"last_received_date\",\n",
    "    \"expiration_date\",\n",
    "    \"product_weight\",\n",
    "    \"order_priority\",\n",
    "    \"vacation_days\",\n",
    "    \"quantity_on_hand\",\n",
    "    \"order_notes\",\n",
    "    \"risk_score\",\n",
    "    \"product_dimensions\",\n",
    "    \"card_type\",\n",
    "    \"overdraft_limit\",\n",
    "    \"loyalty_points\",\n",
    "    \"customer_status\",\n",
    "    \"material\",\n",
    "    \"emergency_contact\",\n",
    "    \"branch_code\",\n",
    "    \"customer_zip\",\n",
    "    \"processing_time\",\n",
    "    \"terminal_id\",\n",
    "    \"quantity_reserved\",\n",
    "    \"department\",\n",
    "    \"transaction_status\",\n",
    "    \"product_cost\",\n",
    "    \"last_transaction_date\",\n",
    "    \"reorder_quantity\",\n",
    "    \"coupon_code\",\n",
    "    \"income_range\",\n",
    "    \"inventory_quantity\",\n",
    "    \"customer_country\",\n",
    "    \"warranty_period\",\n",
    "    \"customer_address\",\n",
    "    \"vendor_id\",\n",
    "    \"size\",\n",
    "    \"shipping_state\",\n",
    "    \"estimated_delivery\",\n",
    "    \"job_title\",\n",
    "    \"preferred_language\",\n",
    "    \"customer_phone\",\n",
    "    \"employee_email\",\n",
    "    \"markup_percentage\",\n",
    "    \"account_currency\",\n",
    "    \"net_amount\",\n",
    "    \"sick_days\",\n",
    "]\n",
    "\n",
    "# Predict top-3 matches\n",
    "top_matches = predict_top_k(model, tokenizer, raw_col, standard_cols, k=3)\n",
    "for match in top_matches:\n",
    "    print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef997c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
